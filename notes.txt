
gemini 2.0 flash
groq.t
remove chatgpt?


notes on how the logistic for router, aggregator, and consensus layer works

->指预期返回类型

main:
初始化setting.py里面setting类里面的open_router_api_key以及open_router_base_url



setting.py:
Message类有role和content


base_router.py:
request是处理http请求的工具，request.session是创立了一个实体，维持某些对话格式

rstrip是为了把/去掉避免后面拼接endpoint出错

CompletionRequest类
适用于一次对话情景，只有一个prompt

ChatRquest类
适用于多次对话以后的返回，list[Message]是一个由多个Message组成的列表，可以让LLM熟悉
较长的上文情景

Base_router类
init
里面setting类里面的open_router_api_key以及open_router_base_url
self.headers(headers是一个字典)用于表示希望接受怎样的返回，基础为application/json，表示希望接受json返回

如果有给定的api_key，那么就在headers里面添加一个Authorization: Bearer {self.api_key}

#url以及headers是request库里面的session实体里面需要有的参数 
header在这里用于表明期望的返回结果。但也可以有认证端信息，客户信息，
以及缓存信息等

get
向api发送请求然后返回一个字典里面的json结构
拼接base_url和endpoint得到完整的链接
.json()是request里面的方法
#param以及json也是session实体里面有的参数，param会被自动拼接到url后面
json会被放在请求的body里面，不会被拼接在url后面，会自动设置header application/json

post
发送大体量的json文件，理解为传输prompt

AsyncbaseRouter类

多了一个await然后在设定AsyncClient的时候就声明了timeout量，async在于可以通过
await实现等待其他函数，不阻塞其他函数的执行

close()调用了aclose关掉了这个AsyncClient的实体，关闭之后不能重新使用这个实体进行
请求，需要重新创建

openrouter.py:

OpenRouterProvider类

get_availables_model
设定endpoint为/models，返回一个字典，每一个key是模型名，value是模型的描述
json文件的格式，里面可以存放json，字典，数组等

get_model_endpoints








